/* Name: Benjamin Shiao
# Date: 4/28/20
# Title: Lab5 â€“ Synchronization using semaphores, lock, and condition variables
# Description: report on lab 5
*/

Step 1: Running the file given for step one made it so the threads critical sections aren't running on the exa
ctly at the same time, kind of running one by one. They are not entering each other's critical sections in order, but they are returning in order. Sometimes multiple threads enter a critical section before threads return and multiple threads return before threads enter critical sections. After all threads return, it prints 'Main thread done". It differs from threadHello.c file because each critical section takes longer time to run and we dont see as many threads begin at once before any threads return. This code runs a bit more one by one with the threads, although not perfectly. Threads wait for other threads' critical sections to complete before entering.

Step 2: My results for my file in step 2 are very similar to that of step 1. The critical sections seem to never run together, as the entire process always lets all 10 threads wait(1) run fully. The threads entering critical sections is not always in order, but often is. Threads returning is always in order. Sometimes multiple threads return before critical sections are entered and sometimes multiple critical sections are entered before threads return. But everyone's critical section runs on their own. Threads wait for other threads' critical sections to complete before entering.

step3: I made multiple producer and consumer threads and when they were running, each thread allowed the other threads to run their critical sections on their own. The result was printing a random number being added or printed to an integer array buffer I declared globally. It would produce or consume going around in a loop, with the consumer behind the producer. This showed me that as I made the producer add items and the consumer print items, each thread would finish reading or adding an item on their own, as if reading/adding was atomic. This makes sure data cant be accessed while someone is accessing/changing data. A few producer operations ran, then a few consumer, and on and on, with a small random amount of operations running each time. Every operation/critical section running was run alone, with no other threads critical sections overlapping. I noticed i needed to have the sem_unlink at the beginning of the code because my code would run forever until i hit ctrl+c due to the nature of the loop. This meant the unlink was never run, unless i put it at the front. I would typically see several consume prints, then several producer prints, each taking 1 second, showing me they ran their critical sections without any overlap. There was always a somewhat random amount of producer and consumer statements that would run before switching. Each critical section ran sleep(1), so every print took 1 second.

Step 4: I had similar output to step 3, but I set the buffer size to 10, so I would see 10 produce prints, then 10 consume, and a repeating system of that. It would produce items at indexes 0-9, each taking 1 second, then print items at indexes 0-9, each taking one second. I saw my program sucessfully edited the buffer. Each print statement had a 1 second delay and that showed me the critical sections were all runing only when no other critical section was running. Every operation/critical section running was run alone, with no other threads critical sections overlapping. Each critical section ran sleep(1), so every print took 1 second.
